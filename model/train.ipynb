{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e5ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from model import  Skeleton2Mesh\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from new_model import DHAmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1000 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     49\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data, batch_targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     51\u001b[0m     batch_data    \u001b[38;5;241m=\u001b[39m batch_data\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     52\u001b[0m     batch_targets \u001b[38;5;241m=\u001b[39m batch_targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:488\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1164\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1171\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dyros\\anaconda3\\envs\\hand\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Imports and Hyperparameters\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_DIM     = 63    # dimension of input feature vector\n",
    "TARGET_DIM    = 3     # dimension of target (joint angles per head)\n",
    "BATCH_SIZE    = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS    = 1000\n",
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Load dataset\n",
    "X_tensor, y_tensor = torch.load('dataset.pt')\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split into train/validation\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "\n",
    "# 3. Model, Loss, Optimizer, Scheduler\n",
    "model     = DHAmodel().to(DEVICE)\n",
    "criterion = nn.MSELoss()    # use MSE for regression\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=NUM_EPOCHS, T_mult=2, eta_min=1e-4\n",
    ")\n",
    "\n",
    "# 4. Training & Validation Loop with tqdm and 10‑epoch logging\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1), desc='Epochs'):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data, batch_targets in train_loader:\n",
    "        batch_data    = batch_data.to(DEVICE)\n",
    "        batch_targets = batch_targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss    = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * batch_data.size(0)\n",
    "    train_loss /= train_size\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_targets in val_loader:\n",
    "            val_data    = val_data.to(DEVICE)\n",
    "            val_targets = val_targets.to(DEVICE)\n",
    "\n",
    "            val_outputs = model(val_data)\n",
    "            v_loss = criterion(val_outputs, val_targets)\n",
    "            val_loss += v_loss.item() * val_data.size(0)\n",
    "    val_loss /= val_size\n",
    "\n",
    "    # --- Scheduler Step ---\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- Logging every 10 epochs ---\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch:04d}/{NUM_EPOCHS:04d}]  \"\n",
    "            f\"Train Loss: {train_loss:.6f}  \"\n",
    "            f\"Val Loss:   {val_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "    # --- Checkpoint Saving every 100 epochs ---\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"dha_model_epoch{epoch}.pth\")\n",
    "\n",
    "# 5. Final Save\n",
    "torch.save(model.state_dict(), \"dha_model_final.pth\")\n",
    "print(\"Training complete. Final model saved to dha_model_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbbe8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "num_joints    = 20\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [512, 512]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "batch_size    = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs    = 1000\n",
    "device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_tensor, y_tensor = torch.load('dataset_2.pt')  # X: [N,182], y: [N]\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "save_interval = 100\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# 4) 모델·옵티마이저·손실함수 초기화\n",
    "model = Skeleton2Mesh(\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs, T_mult=2, eta_min=1e-4)\n",
    "\n",
    "# alpha = 5.0\n",
    "# weights = torch.cat([\n",
    "#     torch.full((1,), 2),\n",
    "#     torch.full((3,), alpha),  # first 4 dims have weight alpha\n",
    "#     torch.ones(4)             # last 4 dims have weight 1.0\n",
    "# ], dim=0).to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c526b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 821/1000 [44:06<09:38,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821 | Train Loss: 0.301170 | Val Loss: 0.622805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 822/1000 [44:10<09:36,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 822 | Train Loss: 0.298610 | Val Loss: 0.622492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 823/1000 [44:13<09:26,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823 | Train Loss: 0.299747 | Val Loss: 0.602296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 824/1000 [44:16<09:18,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824 | Train Loss: 0.305575 | Val Loss: 0.608439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 825/1000 [44:19<09:11,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825 | Train Loss: 0.300619 | Val Loss: 0.636942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 826/1000 [44:22<09:07,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826 | Train Loss: 0.296321 | Val Loss: 0.596421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 827/1000 [44:25<09:05,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827 | Train Loss: 0.297979 | Val Loss: 0.596700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 828/1000 [44:29<09:07,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 828 | Train Loss: 0.301208 | Val Loss: 0.622842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 829/1000 [44:32<09:00,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829 | Train Loss: 0.301745 | Val Loss: 0.603927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 830/1000 [44:35<08:53,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830 | Train Loss: 0.297910 | Val Loss: 0.641811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 831/1000 [44:38<08:48,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831 | Train Loss: 0.304070 | Val Loss: 0.603470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 832/1000 [44:41<08:44,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832 | Train Loss: 0.299164 | Val Loss: 0.647991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 833/1000 [44:44<08:39,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833 | Train Loss: 0.300824 | Val Loss: 0.612910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 834/1000 [44:47<08:36,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834 | Train Loss: 0.299585 | Val Loss: 0.608688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 835/1000 [44:50<08:34,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835 | Train Loss: 0.296728 | Val Loss: 0.610689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 836/1000 [44:53<08:31,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836 | Train Loss: 0.297737 | Val Loss: 0.618694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 837/1000 [44:57<08:28,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837 | Train Loss: 0.296462 | Val Loss: 0.608877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 838/1000 [45:00<08:24,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838 | Train Loss: 0.304863 | Val Loss: 0.649899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 839/1000 [45:03<08:21,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839 | Train Loss: 0.296366 | Val Loss: 0.630173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 840/1000 [45:06<08:18,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840 | Train Loss: 0.296192 | Val Loss: 0.620241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 841/1000 [45:09<08:14,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841 | Train Loss: 0.299282 | Val Loss: 0.608538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 842/1000 [45:12<08:11,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842 | Train Loss: 0.307931 | Val Loss: 0.613565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 843/1000 [45:15<08:07,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843 | Train Loss: 0.295058 | Val Loss: 0.618165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 844/1000 [45:18<08:04,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 844 | Train Loss: 0.298431 | Val Loss: 0.609624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 845/1000 [45:21<08:02,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845 | Train Loss: 0.300592 | Val Loss: 0.661531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 846/1000 [45:25<07:59,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846 | Train Loss: 0.295088 | Val Loss: 0.626787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 847/1000 [45:28<07:56,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847 | Train Loss: 0.295012 | Val Loss: 0.590836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 848/1000 [45:31<07:53,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848 | Train Loss: 0.297348 | Val Loss: 0.589250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 849/1000 [45:34<07:51,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849 | Train Loss: 0.301103 | Val Loss: 0.599420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/1000 [45:37<07:48,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850 | Train Loss: 0.295359 | Val Loss: 0.683811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [45:40<07:45,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851 | Train Loss: 0.299727 | Val Loss: 0.607465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [45:43<07:42,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 852 | Train Loss: 0.293358 | Val Loss: 0.584665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 853/1000 [45:46<07:40,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853 | Train Loss: 0.297306 | Val Loss: 0.597444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 854/1000 [45:50<07:40,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854 | Train Loss: 0.299820 | Val Loss: 0.608009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 855/1000 [45:53<07:35,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855 | Train Loss: 0.292051 | Val Loss: 0.586385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 856/1000 [45:56<07:34,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856 | Train Loss: 0.293730 | Val Loss: 0.625716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 857/1000 [45:59<07:30,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857 | Train Loss: 0.302877 | Val Loss: 0.653802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 858/1000 [46:02<07:28,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 858 | Train Loss: 0.292013 | Val Loss: 0.608984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 859/1000 [46:06<07:28,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 859 | Train Loss: 0.295071 | Val Loss: 0.626452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 860/1000 [46:09<07:24,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860 | Train Loss: 0.298365 | Val Loss: 0.596747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 861/1000 [46:12<07:30,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 861 | Train Loss: 0.292665 | Val Loss: 0.597314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 862/1000 [46:15<07:24,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862 | Train Loss: 0.297540 | Val Loss: 0.611538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 863/1000 [46:18<07:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863 | Train Loss: 0.299640 | Val Loss: 0.598931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 864/1000 [46:22<07:15,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 864 | Train Loss: 0.295700 | Val Loss: 0.605178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 865/1000 [46:25<07:19,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 865 | Train Loss: 0.292035 | Val Loss: 0.601870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 866/1000 [46:28<07:23,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 866 | Train Loss: 0.299340 | Val Loss: 0.592109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 867/1000 [46:32<07:15,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 867 | Train Loss: 0.291395 | Val Loss: 0.591019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 868/1000 [46:35<07:14,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868 | Train Loss: 0.295044 | Val Loss: 0.612661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 869/1000 [46:38<07:09,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869 | Train Loss: 0.297992 | Val Loss: 0.597919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 870/1000 [46:42<07:06,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870 | Train Loss: 0.292478 | Val Loss: 0.610669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 871/1000 [46:45<07:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871 | Train Loss: 0.296289 | Val Loss: 0.585352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 872/1000 [46:48<06:59,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 872 | Train Loss: 0.287413 | Val Loss: 0.579843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 873/1000 [46:51<06:53,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873 | Train Loss: 0.296259 | Val Loss: 0.590900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 874/1000 [46:54<06:48,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874 | Train Loss: 0.292614 | Val Loss: 0.609551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 875/1000 [46:58<06:46,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875 | Train Loss: 0.295638 | Val Loss: 0.607468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 876/1000 [47:01<06:43,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 876 | Train Loss: 0.292886 | Val Loss: 0.625338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 877/1000 [47:04<06:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 877 | Train Loss: 0.295142 | Val Loss: 0.600041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 878/1000 [47:08<06:37,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 878 | Train Loss: 0.292276 | Val Loss: 0.618857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 879/1000 [47:11<06:34,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879 | Train Loss: 0.294925 | Val Loss: 0.601200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 880/1000 [47:14<06:36,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880 | Train Loss: 0.292295 | Val Loss: 0.598793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 881/1000 [47:17<06:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881 | Train Loss: 0.289773 | Val Loss: 0.653201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 882/1000 [47:21<06:25,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 882 | Train Loss: 0.289380 | Val Loss: 0.575903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 883/1000 [47:24<06:21,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 883 | Train Loss: 0.295045 | Val Loss: 0.614744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 884/1000 [47:27<06:21,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884 | Train Loss: 0.292950 | Val Loss: 0.599015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 885/1000 [47:31<06:18,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885 | Train Loss: 0.292834 | Val Loss: 0.603701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 886/1000 [47:34<06:12,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886 | Train Loss: 0.291304 | Val Loss: 0.614050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 887/1000 [47:37<06:07,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887 | Train Loss: 0.287303 | Val Loss: 0.627491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 888/1000 [47:40<06:05,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888 | Train Loss: 0.298557 | Val Loss: 0.608505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 889/1000 [47:44<06:05,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889 | Train Loss: 0.296022 | Val Loss: 0.600167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 890/1000 [47:47<05:59,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890 | Train Loss: 0.288956 | Val Loss: 0.616854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 891/1000 [47:50<05:56,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891 | Train Loss: 0.288465 | Val Loss: 0.607413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 892/1000 [47:53<05:53,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892 | Train Loss: 0.293737 | Val Loss: 0.599761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 893/1000 [47:57<05:51,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893 | Train Loss: 0.292500 | Val Loss: 0.622057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 894/1000 [48:00<05:51,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894 | Train Loss: 0.291478 | Val Loss: 0.635467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 895/1000 [48:03<05:47,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895 | Train Loss: 0.290684 | Val Loss: 0.596911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 896/1000 [48:07<05:44,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896 | Train Loss: 0.291591 | Val Loss: 0.603925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 897/1000 [48:10<05:42,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897 | Train Loss: 0.291213 | Val Loss: 0.626991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 898/1000 [48:13<05:40,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898 | Train Loss: 0.287539 | Val Loss: 0.583467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 899/1000 [48:17<05:32,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899 | Train Loss: 0.292247 | Val Loss: 0.623880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [48:20<05:27,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900 | Train Loss: 0.294257 | Val Loss: 0.609546\n",
      "Checkpoint saved to checkpoint_euler_epoch900_ver6.pth (epoch 900, loss 0.609546)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [48:23<05:23,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901 | Train Loss: 0.284407 | Val Loss: 0.598008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [48:26<05:17,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902 | Train Loss: 0.289023 | Val Loss: 0.604145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 903/1000 [48:30<05:13,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 903 | Train Loss: 0.288471 | Val Loss: 0.605849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 904/1000 [48:33<05:09,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904 | Train Loss: 0.293734 | Val Loss: 0.588723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 905/1000 [48:36<05:05,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 905 | Train Loss: 0.288092 | Val Loss: 0.610844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 906/1000 [48:39<05:01,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906 | Train Loss: 0.289821 | Val Loss: 0.646745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 907/1000 [48:42<04:57,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 907 | Train Loss: 0.287061 | Val Loss: 0.636443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 908/1000 [48:46<04:54,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 908 | Train Loss: 0.290298 | Val Loss: 0.626266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 909/1000 [48:49<04:50,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909 | Train Loss: 0.283948 | Val Loss: 0.597754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 910/1000 [48:52<04:47,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910 | Train Loss: 0.289884 | Val Loss: 0.595384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 911/1000 [48:55<04:45,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911 | Train Loss: 0.288375 | Val Loss: 0.609230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 912/1000 [48:58<04:45,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912 | Train Loss: 0.288032 | Val Loss: 0.602769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 913/1000 [49:02<04:43,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913 | Train Loss: 0.291729 | Val Loss: 0.610356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 914/1000 [49:05<04:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914 | Train Loss: 0.293399 | Val Loss: 0.573988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 915/1000 [49:08<04:39,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915 | Train Loss: 0.285703 | Val Loss: 0.616794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 916/1000 [49:12<04:39,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916 | Train Loss: 0.289536 | Val Loss: 0.590915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 917/1000 [49:15<04:36,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917 | Train Loss: 0.290878 | Val Loss: 0.590255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 918/1000 [49:18<04:32,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 918 | Train Loss: 0.285776 | Val Loss: 0.598687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 919/1000 [49:22<04:27,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919 | Train Loss: 0.285878 | Val Loss: 0.596310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 920/1000 [49:25<04:21,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920 | Train Loss: 0.288787 | Val Loss: 0.599184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 921/1000 [49:28<04:16,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921 | Train Loss: 0.287059 | Val Loss: 0.621436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 922/1000 [49:31<04:12,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922 | Train Loss: 0.287037 | Val Loss: 0.630780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 923/1000 [49:35<04:08,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923 | Train Loss: 0.287880 | Val Loss: 0.602544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 924/1000 [49:38<04:04,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924 | Train Loss: 0.283816 | Val Loss: 0.604442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 925/1000 [49:41<04:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925 | Train Loss: 0.284208 | Val Loss: 0.586080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 926/1000 [49:44<03:56,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926 | Train Loss: 0.286686 | Val Loss: 0.607996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 927/1000 [49:47<03:53,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927 | Train Loss: 0.287522 | Val Loss: 0.625444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 928/1000 [49:50<03:49,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928 | Train Loss: 0.291626 | Val Loss: 0.601445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 929/1000 [49:54<03:46,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929 | Train Loss: 0.284591 | Val Loss: 0.579687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 930/1000 [49:57<03:42,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930 | Train Loss: 0.283839 | Val Loss: 0.605145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 931/1000 [50:00<03:39,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 931 | Train Loss: 0.293777 | Val Loss: 0.635254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 932/1000 [50:03<03:37,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 932 | Train Loss: 0.284218 | Val Loss: 0.600389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 933/1000 [50:06<03:34,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 933 | Train Loss: 0.288676 | Val Loss: 0.610367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 934/1000 [50:10<03:31,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934 | Train Loss: 0.285917 | Val Loss: 0.598189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 935/1000 [50:13<03:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935 | Train Loss: 0.286654 | Val Loss: 0.597219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 936/1000 [50:16<03:26,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936 | Train Loss: 0.282547 | Val Loss: 0.613578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 937/1000 [50:19<03:25,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937 | Train Loss: 0.283610 | Val Loss: 0.597625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 938/1000 [50:23<03:22,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938 | Train Loss: 0.288187 | Val Loss: 0.609416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 939/1000 [50:26<03:19,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939 | Train Loss: 0.288192 | Val Loss: 0.606665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 940/1000 [50:29<03:17,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940 | Train Loss: 0.284190 | Val Loss: 0.628511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 941/1000 [50:33<03:15,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941 | Train Loss: 0.285593 | Val Loss: 0.599720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 942/1000 [50:36<03:12,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 942 | Train Loss: 0.284861 | Val Loss: 0.593036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 943/1000 [50:39<03:08,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943 | Train Loss: 0.288810 | Val Loss: 0.616275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 944/1000 [50:42<03:02,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944 | Train Loss: 0.288229 | Val Loss: 0.585369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 945/1000 [50:46<02:57,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945 | Train Loss: 0.286298 | Val Loss: 0.594646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 946/1000 [50:49<02:53,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946 | Train Loss: 0.281827 | Val Loss: 0.587999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 947/1000 [50:52<02:50,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947 | Train Loss: 0.284860 | Val Loss: 0.587459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 948/1000 [50:55<02:47,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948 | Train Loss: 0.281179 | Val Loss: 0.625807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 949/1000 [50:58<02:43,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949 | Train Loss: 0.287220 | Val Loss: 0.638632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/1000 [51:02<02:40,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950 | Train Loss: 0.281904 | Val Loss: 0.624228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [51:05<02:38,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951 | Train Loss: 0.287998 | Val Loss: 0.591705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 952/1000 [51:08<02:36,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952 | Train Loss: 0.280250 | Val Loss: 0.587688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 953/1000 [51:12<02:34,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953 | Train Loss: 0.287511 | Val Loss: 0.600979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 954/1000 [51:15<02:32,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954 | Train Loss: 0.285185 | Val Loss: 0.583224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 955/1000 [51:18<02:29,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955 | Train Loss: 0.280152 | Val Loss: 0.613619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 956/1000 [51:22<02:26,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 956 | Train Loss: 0.286553 | Val Loss: 0.585730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 957/1000 [51:25<02:23,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957 | Train Loss: 0.283871 | Val Loss: 0.606693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 958/1000 [51:28<02:20,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 958 | Train Loss: 0.285218 | Val Loss: 0.603184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 959/1000 [51:32<02:16,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959 | Train Loss: 0.285154 | Val Loss: 0.587507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 960/1000 [51:35<02:11,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960 | Train Loss: 0.280239 | Val Loss: 0.611543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 961/1000 [51:38<02:07,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961 | Train Loss: 0.286420 | Val Loss: 0.598127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 962/1000 [51:41<02:03,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962 | Train Loss: 0.287350 | Val Loss: 0.588477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 963/1000 [51:45<01:59,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963 | Train Loss: 0.279995 | Val Loss: 0.605874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 964/1000 [51:48<01:55,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964 | Train Loss: 0.284572 | Val Loss: 0.617126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 965/1000 [51:51<01:52,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 965 | Train Loss: 0.282677 | Val Loss: 0.597609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 966/1000 [51:54<01:49,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 966 | Train Loss: 0.282917 | Val Loss: 0.611501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 967/1000 [51:57<01:46,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 967 | Train Loss: 0.278954 | Val Loss: 0.618573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 968/1000 [52:01<01:43,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968 | Train Loss: 0.281319 | Val Loss: 0.608542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 969/1000 [52:04<01:40,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969 | Train Loss: 0.283181 | Val Loss: 0.585885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 970/1000 [52:07<01:37,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970 | Train Loss: 0.283225 | Val Loss: 0.648519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 971/1000 [52:10<01:33,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971 | Train Loss: 0.279529 | Val Loss: 0.616438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 972/1000 [52:14<01:30,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972 | Train Loss: 0.287099 | Val Loss: 0.585582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 973/1000 [52:17<01:27,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973 | Train Loss: 0.281301 | Val Loss: 0.618716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 974/1000 [52:20<01:25,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 974 | Train Loss: 0.283337 | Val Loss: 0.647026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 975/1000 [52:24<01:22,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 975 | Train Loss: 0.280959 | Val Loss: 0.591073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 976/1000 [52:27<01:19,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976 | Train Loss: 0.279912 | Val Loss: 0.594063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 977/1000 [52:30<01:15,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 977 | Train Loss: 0.278879 | Val Loss: 0.604886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 978/1000 [52:33<01:12,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978 | Train Loss: 0.286283 | Val Loss: 0.584404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 979/1000 [52:37<01:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 979 | Train Loss: 0.276281 | Val Loss: 0.596561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 980/1000 [52:40<01:06,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980 | Train Loss: 0.281190 | Val Loss: 0.593132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [52:44<01:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981 | Train Loss: 0.281088 | Val Loss: 0.620908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 982/1000 [52:47<01:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982 | Train Loss: 0.279693 | Val Loss: 0.578718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 983/1000 [52:50<00:56,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983 | Train Loss: 0.274631 | Val Loss: 0.585745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 984/1000 [52:54<00:53,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984 | Train Loss: 0.285085 | Val Loss: 0.582898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 985/1000 [52:57<00:49,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985 | Train Loss: 0.282361 | Val Loss: 0.597016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 986/1000 [53:00<00:45,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 986 | Train Loss: 0.278115 | Val Loss: 0.629198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 987/1000 [53:03<00:42,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987 | Train Loss: 0.281757 | Val Loss: 0.611237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 988/1000 [53:07<00:39,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988 | Train Loss: 0.281759 | Val Loss: 0.589138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 989/1000 [53:10<00:35,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989 | Train Loss: 0.276592 | Val Loss: 0.598629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 990/1000 [53:13<00:32,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990 | Train Loss: 0.276181 | Val Loss: 0.613408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 991/1000 [53:16<00:29,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991 | Train Loss: 0.280648 | Val Loss: 0.597180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 992/1000 [53:19<00:25,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 992 | Train Loss: 0.277469 | Val Loss: 0.588765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 993/1000 [53:23<00:22,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993 | Train Loss: 0.279923 | Val Loss: 0.586902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 994/1000 [53:26<00:19,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994 | Train Loss: 0.278079 | Val Loss: 0.613294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 995/1000 [53:29<00:16,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 995 | Train Loss: 0.278409 | Val Loss: 0.620404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 996/1000 [53:33<00:13,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 996 | Train Loss: 0.280209 | Val Loss: 0.614614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 997/1000 [53:36<00:09,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997 | Train Loss: 0.276260 | Val Loss: 0.611106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 998/1000 [53:39<00:06,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 998 | Train Loss: 0.281550 | Val Loss: 0.570397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 999/1000 [53:43<00:03,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999 | Train Loss: 0.276299 | Val Loss: 0.580788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [53:46<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Train Loss: 0.275144 | Val Loss: 0.596141\n",
      "Checkpoint saved to checkpoint_euler_epoch1000_ver6.pth (epoch 1000, loss 0.596141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 5. Usage example in training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# weights_sum = weights.sum()\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "   model.train()\n",
    "   train_loss = 0.0\n",
    "   for skeletons_flat_batch, angles_batch in train_loader:\n",
    "       skeletons_flat_batch = skeletons_flat_batch.to(device)\n",
    "       angles_batch         = angles_batch.to(device)\n",
    "\n",
    "       preds = model(skeletons_flat_batch)     # [B,8]\n",
    "       loss  = criterion(preds, angles_batch)\n",
    "\n",
    "    #    loss_per_sample = (loss_matrix * weights).sum(dim=1) / weights_sum\n",
    "    #    loss = loss_per_sample.mean()\n",
    "    \n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "\n",
    "       train_loss += loss.item() * skeletons_flat_batch.size(0)\n",
    "\n",
    "   train_loss /= train_size\n",
    "\n",
    "   # 6) 검증\n",
    "   model.eval()\n",
    "   val_loss = 0.0\n",
    "   with torch.no_grad():\n",
    "       for skeletons_flat_batch, angles_batch in val_loader:\n",
    "           skeletons_flat_batch = skeletons_flat_batch.to(device)\n",
    "           angles_batch         = angles_batch.to(device)\n",
    "\n",
    "           preds = model(skeletons_flat_batch)\n",
    "           lm = criterion(preds, angles_batch)\n",
    "        #    lps = (lm * weights).sum(dim=1) / weights_sum\n",
    "        #    loss_v = lps.mean()\n",
    "\n",
    "           val_loss += lm.item() * skeletons_flat_batch.size(0)\n",
    "   val_loss /= val_size\n",
    "\n",
    "   print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "# Example variables: epoch (int), model (nn.Module), optimizer (Optimizer), loss_value (float)\n",
    "# Adjust 'checkpoint_path' as 원하는 파일명 또는 경로로 변경하세요.\n",
    "   if epoch % save_interval == 0 or epoch == num_epochs:\n",
    "       checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss\n",
    "            }\n",
    "\n",
    "       checkpoint_path = 'checkpoint_euler_epoch{}_ver6.pth'.format(epoch)\n",
    "       torch.save(checkpoint, checkpoint_path)\n",
    "       print(f\"Checkpoint saved to {checkpoint_path} (epoch {epoch}, loss {val_loss:.6f})\")\n",
    "   scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95e8e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 32 arrays to euler_epoch1000_ver6.npz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1) Load the checkpoint from .pth file\n",
    "#    If the file contains a dict with 'model_state_dict', use that;\n",
    "#    otherwise assume it _is_ the state_dict.\n",
    "checkpoint = torch.load('checkpoint_euler_epoch1000_ver6.pth', map_location='cpu')\n",
    "state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "\n",
    "# 2) Convert each tensor in the state_dict to a NumPy array\n",
    "np_params = {}\n",
    "for name, tensor in state_dict.items():\n",
    "    # Ensure the tensor is on CPU and convert to numpy\n",
    "    np_params[name] = tensor.detach().cpu().numpy()\n",
    "\n",
    "# 3) Save all arrays into a single .npz file\n",
    "#    Keys in the archive will match the original parameter names.\n",
    "np.savez('euler_epoch1000_ver6.npz', **np_params)\n",
    "\n",
    "print(f\"Saved {len(np_params)} arrays to euler_epoch1000_ver6.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa28ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (mean over all outputs): 17.628642\n",
      "Test MAE (mean over all outputs): 3.184651\n",
      "Per-output RMSE: [4.531677  4.2525287 3.7770135]\n",
      "Per-output MAE:  [3.6913805 3.108207  2.7543647]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Load test data\n",
    "X_test, y_test = torch.load('test.pt',weights_only=False)\n",
    "\n",
    "# 1) Device 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3) Hyperparameters / model config\n",
    "num_joints    = 20\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [512, 512]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "# 4) Instantiate model and load checkpoint\n",
    "model = Skeleton2Mesh(\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ").to(device)\n",
    "\n",
    "# Path to saved checkpoint\n",
    "checkpoint_path = \"checkpoint_euler_epoch1000_ver4.pth\"  # 실제 파일명으로 변경\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# If optimizer state or epoch 등 추가 정보가 필요하면\n",
    "# epoch_loaded = checkpoint.get('epoch')\n",
    "# loss_loaded = checkpoint.get('loss')\n",
    "\n",
    "# 5) Prepare test data\n",
    "#    Assume you have NumPy arrays:\n",
    "#      skeletons_test_np: shape [N_test, num_joints*3]\n",
    "#      angles_test_np:    shape [N_test, 8]\n",
    "#    These must be prepared beforehand.\n",
    "import numpy as np\n",
    "# Example placeholders; 실제 데이터를 여기에 할당하세요.\n",
    "# skeletons_test_np = np.load(\"skeletons_test.npy\")  # [N_test, 63]\n",
    "# angles_test_np    = np.load(\"angles_test.npy\")     # [N_test, 8]\n",
    "\n",
    "# Convert to torch.Tensor\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64  # 필요에 따라 변경\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 6) Define evaluation metrics\n",
    "mse_loss_fn = nn.MSELoss(reduction='mean')\n",
    "mae_loss_fn = nn.L1Loss(reduction='mean')\n",
    "\n",
    "# Optional: per-dimension metrics\n",
    "num_outputs = y_test.shape[1]  # e.g. 8\n",
    "\n",
    "# Containers for aggregated results\n",
    "total_mse = 0.0\n",
    "total_mae = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "# If you want per-output errors, accumulate sums:\n",
    "sum_sq_errors = torch.zeros(num_outputs, device=device)\n",
    "sum_abs_errors = torch.zeros(num_outputs, device=device)\n",
    "\n",
    "# 7) Evaluation loop\n",
    "with torch.no_grad():\n",
    "    for skeletons_flat_batch, angles_batch in test_loader:\n",
    "        skeletons_flat_batch = skeletons_flat_batch.to(device)  # [B, num_joints*3]\n",
    "        angles_batch         = angles_batch.to(device)         # [B, 8]\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(skeletons_flat_batch)  # [B, 8]\n",
    "\n",
    "        # Compute batch losses\n",
    "        batch_mse = mse_loss_fn(preds, angles_batch)  # scalar\n",
    "        batch_mae = mae_loss_fn(preds, angles_batch)  # scalar\n",
    "\n",
    "        # Accumulate weighted by batch size\n",
    "        B = skeletons_flat_batch.size(0)\n",
    "        total_mse += batch_mse.item() * B\n",
    "        total_mae += batch_mae.item() * B\n",
    "        num_samples += B\n",
    "\n",
    "        # Per-output accumulation\n",
    "        # Compute squared error and abs error per sample per dimension\n",
    "        diff = preds - angles_batch  # [B, 8]\n",
    "        sum_sq_errors += torch.sum(diff * diff, dim=0)    # [8]\n",
    "        sum_abs_errors += torch.sum(torch.abs(diff), dim=0)  # [8]\n",
    "\n",
    "# 8) Final metrics\n",
    "mean_mse = total_mse / num_samples\n",
    "mean_mae = total_mae / num_samples\n",
    "\n",
    "# Per-output RMSE and MAE\n",
    "rmse_per_output = torch.sqrt(sum_sq_errors / num_samples)  # [8]\n",
    "mae_per_output  = sum_abs_errors / num_samples            # [8]\n",
    "\n",
    "print(f\"Test MSE (mean over all outputs): {mean_mse:.6f}\")\n",
    "print(f\"Test MAE (mean over all outputs): {mean_mae:.6f}\")\n",
    "print(\"Per-output RMSE:\", rmse_per_output.cpu().numpy())\n",
    "print(\"Per-output MAE: \", mae_per_output.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee24649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5914709288046258\n",
      "1.1021885039348363\n",
      "0.8683562051886073\n",
      "0.8026795895274358\n",
      "0.7498973137366941\n",
      "0.66938524580282\n",
      "0.647677368512254\n",
      "0.5822166961597856\n",
      "0.5836499552460582\n",
      "0.5837646077133342\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "# Path to saved checkpoint\n",
    "    checkpoint_path = f\"checkpoint_euler_epoch{i*100}_ver4.pth\"  # 실제 파일명으로 변경\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(checkpoint['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40824381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib              # joblib is better for sklearn objects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) Load the fitted scaler\n",
    "scaler = joblib.load('y_scaler.pkl')\n",
    "\n",
    "# 2) Inverse transform normalized predictions and targets\n",
    "\n",
    "\n",
    "# 3) Compute MSE on denormalized values\n",
    "mse_per_output_denorm = mean_squared_error(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    multioutput='raw_values'\n",
    ")\n",
    "avg_mse_denorm = np.mean(mse_per_output_denorm)\n",
    "print(\"Denormalized MSE per output:\", mse_per_output_denorm)\n",
    "print(f\"Average denormalized MSE: {avg_mse_denorm:.4f}\")\n",
    "\n",
    "# 4) Build comparison DataFrame\n",
    "num_outputs = y_true.shape[1]\n",
    "columns = [f\"true_{i}\" for i in range(num_outputs)] + [f\"pred_{i}\" for i in range(num_outputs)]\n",
    "df_compare = pd.DataFrame(\n",
    "    np.hstack([y_true, y_pred]),\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# 5) Inspect a specific row by index\n",
    "index_to_inspect = 1293  # ← change this to the row you want\n",
    "if not (0 <= index_to_inspect < len(df_compare)):\n",
    "    raise IndexError(f\"Index out of range: 0 ≤ idx < {len(df_compare)}\")\n",
    "\n",
    "print(f\"\\nComparison at index {index_to_inspect}:\")\n",
    "print(df_compare.loc[[index_to_inspect]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7525e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(mse_per_output, bins=10, edgecolor='black')\n",
    "plt.title('Histogram of MSE per Output')\n",
    "plt.xlabel('MSE Value')\n",
    "plt.ylabel('Number of Outputs')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_and_save_s2m_weights(pth_path: str,\n",
    "                                 output_npz_path: str,\n",
    "                                 num_joints: int,\n",
    "                                 num_bones: int,\n",
    "                                 gsd_dim: int,\n",
    "                                 mlp_hidden: list,\n",
    "                                 pe_freqs_bone: int,\n",
    "                                 pe_freqs_order: int):\n",
    "    \"\"\"\n",
    "    Load a Skeleton2Mesh checkpoint from pth_path, extract all model weights\n",
    "    into NumPy arrays, and save into output_npz_path (.npz).\n",
    "\n",
    "    Args:\n",
    "      pth_path: path to the .pth checkpoint (must contain 'model_state_dict' key).\n",
    "      output_npz_path: path (including filename) where to save the .npz file.\n",
    "      num_joints, num_bones, gsd_dim, mlp_hidden, pe_freqs_bone, pe_freqs_order:\n",
    "        the hyperparameters used to instantiate the model exactly as in training.\n",
    "    \"\"\"\n",
    "    # 1) Instantiate the model with the same config used during training\n",
    "    model = Skeleton2Mesh(\n",
    "        num_joints=num_joints,\n",
    "        num_bones=num_bones,\n",
    "        gsd_dim=gsd_dim,\n",
    "        mlp_hidden=mlp_hidden,\n",
    "        pe_freqs_bone=pe_freqs_bone,\n",
    "        pe_freqs_order=pe_freqs_order\n",
    "    )\n",
    "    # 2) Load checkpoint (map to CPU to avoid GPU dependency here)\n",
    "    checkpoint = torch.load(pth_path, map_location='cpu')\n",
    "    # Expect checkpoint to have 'model_state_dict'; if your checkpoint saved differently,\n",
    "    # adjust the key accordingly.\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        # If you saved the entire model state_dict directly:\n",
    "        state_dict = checkpoint\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # 3) Extract weights to NumPy arrays\n",
    "    np_params = {}\n",
    "    for name, param in model.state_dict().items():\n",
    "        # detach and move to CPU, then to NumPy float32\n",
    "        np_params[name] = param.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # 4) Save into .npz\n",
    "    np.savez(output_npz_path, **np_params)\n",
    "    print(f\"Saved {len(np_params)} arrays to {output_npz_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assume you have a checkpoint at 's2m_epoch100.pth'\n",
    "# and you used these hyperparameters during training:\n",
    "num_joints    = 20    # as in your code\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [256, 256]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "checkpoint_path = 'checkpoint_ori_epoch1800.pth'   # change to your actual checkpoint filename\n",
    "output_npz_path = 'skeleton2angle_ori.npz'\n",
    "\n",
    "extract_and_save_s2m_weights(\n",
    "    pth_path=checkpoint_path,\n",
    "    output_npz_path=output_npz_path,\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc76e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .npz file: euler_epoch1000.npz\n",
      "Found 32 arrays:\n",
      "\n",
      "  - orientation_embed.weight: shape=(3, 3), dtype=float32 => likely Linear.weight\n",
      "  - orientation_embed.bias: shape=(3,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - gsd_mlp.0.weight: shape=(256, 60), dtype=float32 => likely Linear.weight\n",
      "  - gsd_mlp.0.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - gsd_mlp.2.weight: shape=(256, 256), dtype=float32 => likely Linear.weight\n",
      "  - gsd_mlp.2.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - gsd_mlp.4.weight: shape=(100, 256), dtype=float32 => likely Linear.weight\n",
      "  - gsd_mlp.4.bias: shape=(100,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head1.0.weight: shape=(256, 239), dtype=float32 => likely Linear.weight\n",
      "  - head1.0.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head1.2.weight: shape=(256, 256), dtype=float32 => likely Linear.weight\n",
      "  - head1.2.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head1.4.weight: shape=(1, 256), dtype=float32 => likely Linear.weight\n",
      "  - head1.4.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head2.0.weight: shape=(256, 239), dtype=float32 => likely Linear.weight\n",
      "  - head2.0.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head2.2.weight: shape=(256, 256), dtype=float32 => likely Linear.weight\n",
      "  - head2.2.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head2.4.weight: shape=(1, 256), dtype=float32 => likely Linear.weight\n",
      "  - head2.4.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head3.0.weight: shape=(256, 239), dtype=float32 => likely Linear.weight\n",
      "  - head3.0.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head3.2.weight: shape=(256, 256), dtype=float32 => likely Linear.weight\n",
      "  - head3.2.bias: shape=(256,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - head3.4.weight: shape=(1, 256), dtype=float32 => likely Linear.weight\n",
      "  - head3.4.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - pool1.weight: shape=(1, 19), dtype=float32 => likely Linear.weight\n",
      "  - pool1.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - pool2.weight: shape=(1, 19), dtype=float32 => likely Linear.weight\n",
      "  - pool2.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "  - pool3.weight: shape=(1, 19), dtype=float32 => likely Linear.weight\n",
      "  - pool3.bias: shape=(1,), dtype=float32 => 1D bias: LayerNorm.bias or Linear.bias\n",
      "\n",
      "Additional check for 1D bias vs LayerNorm.bias:\n",
      "  - orientation_embed.bias: shape=(3,) => No matching weight key; unknown\n",
      "  - gsd_mlp.0.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - gsd_mlp.2.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - gsd_mlp.4.bias: shape=(100,) => No matching weight key; unknown\n",
      "  - head1.0.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head1.2.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head1.4.bias: shape=(1,) => No matching weight key; unknown\n",
      "  - head2.0.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head2.2.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head2.4.bias: shape=(1,) => No matching weight key; unknown\n",
      "  - head3.0.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head3.2.bias: shape=(256,) => No matching weight key; unknown\n",
      "  - head3.4.bias: shape=(1,) => No matching weight key; unknown\n",
      "  - pool1.bias: shape=(1,) => No matching weight key; unknown\n",
      "  - pool2.bias: shape=(1,) => No matching weight key; unknown\n",
      "  - pool3.bias: shape=(1,) => No matching weight key; unknown\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with your actual .npz path\n",
    "npz_path = 'euler_epoch1000.npz'\n",
    "\n",
    "try:\n",
    "    data = np.load(npz_path)\n",
    "    print(f\"Loaded .npz file: {npz_path}\")\n",
    "    print(f\"Found {len(data.files)} arrays:\\n\")\n",
    "\n",
    "    for key in data.files:\n",
    "        arr = data[key]\n",
    "        shape = arr.shape\n",
    "        ndim = arr.ndim\n",
    "\n",
    "        # Heuristic classification:\n",
    "        if ndim == 2:\n",
    "            # 2D weight: likely Linear.weight\n",
    "            # shape = (out_features, in_features)\n",
    "            print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => likely Linear.weight\")\n",
    "        elif ndim == 1:\n",
    "            # 1D: could be LayerNorm.weight or LayerNorm.bias or Linear.bias.\n",
    "            # 추가적으로 이름으로 유추:\n",
    "            if key.endswith('.weight'):\n",
    "                # 1D weight: if preceding layer is LayerNorm(prev_dim), then this is LayerNorm.weight.\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D weight: likely LayerNorm.weight\")\n",
    "            elif key.endswith('.bias'):\n",
    "                # 1D bias: could be LayerNorm.bias or Linear.bias.\n",
    "                # 이름만으로 구분이 어려우므로, 앞의 인덱스와 shape를 보고 추론 필요.\n",
    "                # 예: ffn.0.bias shape=(182,)인데, ffn.0.weight도 (182,)이므로 LayerNorm.bias.\n",
    "                #     ffn.1.bias shape=(512,)인데 weight shape (512,182)이면 Linear.bias.\n",
    "                # 간단히 두 가지 모두 가능하다고 표시:\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D bias: LayerNorm.bias or Linear.bias\")\n",
    "            else:\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D array: unknown role\")\n",
    "        else:\n",
    "            print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => unexpected ndim={ndim}\")\n",
    "\n",
    "    # 추가로, 1D bias가 Linear.bias인지 LayerNorm.bias인지 정확히 구분하려면:\n",
    "    print(\"\\nAdditional check for 1D bias vs LayerNorm.bias:\")\n",
    "    for key in data.files:\n",
    "        if key.endswith('.bias') and data[key].ndim == 1:\n",
    "            idx = key.split('.')[1]  # 'ffn.<idx>.bias'\n",
    "            weight_key = f\"ffn.{idx}.weight\"\n",
    "            if weight_key in data.files:\n",
    "                w = data[weight_key]\n",
    "                if w.ndim == 1 and w.shape == data[key].shape:\n",
    "                    # weight도 1D, bias shape 같음 → LayerNorm.bias\n",
    "                    role = \"LayerNorm.bias (matched 1D weight)\"\n",
    "                elif w.ndim == 2 and w.shape[0] == data[key].shape[0]:\n",
    "                    # weight is 2D with out_features equal bias length → Linear.bias\n",
    "                    role = \"Linear.bias (matched 2D weight out_features)\"\n",
    "                else:\n",
    "                    role = \"Unknown bias role\"\n",
    "            else:\n",
    "                role = \"No matching weight key; unknown\"\n",
    "            print(f\"  - {key}: shape={data[key].shape} => {role}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {npz_path}. Please ensure the file exists or update the path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or processing the npz file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
