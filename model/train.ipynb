{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e5ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from model import  Skeleton2Mesh\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from new_model import DHAmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports and Hyperparameters\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_DIM     = 63    # dimension of input feature vector\n",
    "TARGET_DIM    = 3     # dimension of target (joint angles per head)\n",
    "BATCH_SIZE    = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS    = 1000\n",
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Load dataset\n",
    "X_tensor, y_tensor = torch.load('dataset.pt')\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split into train/validation\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "\n",
    "# 3. Model, Loss, Optimizer, Scheduler\n",
    "model     = DHAmodel().to(DEVICE)\n",
    "criterion = nn.MSELoss()    # use MSE for regression\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=NUM_EPOCHS, T_mult=2, eta_min=1e-4\n",
    ")\n",
    "\n",
    "# 4. Training & Validation Loop with tqdm and 10‑epoch logging\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1), desc='Epochs'):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_data, batch_targets in train_loader:\n",
    "        batch_data    = batch_data.to(DEVICE)\n",
    "        batch_targets = batch_targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data)\n",
    "        loss    = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * batch_data.size(0)\n",
    "    train_loss /= train_size\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_targets in val_loader:\n",
    "            val_data    = val_data.to(DEVICE)\n",
    "            val_targets = val_targets.to(DEVICE)\n",
    "\n",
    "            val_outputs = model(val_data)\n",
    "            v_loss = criterion(val_outputs, val_targets)\n",
    "            val_loss += v_loss.item() * val_data.size(0)\n",
    "    val_loss /= val_size\n",
    "\n",
    "    # --- Scheduler Step ---\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- Logging every 10 epochs ---\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch:04d}/{NUM_EPOCHS:04d}]  \"\n",
    "            f\"Train Loss: {train_loss:.6f}  \"\n",
    "            f\"Val Loss:   {val_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "    # --- Checkpoint Saving every 100 epochs ---\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"dha_model_epoch{epoch}.pth\")\n",
    "\n",
    "# 5. Final Save\n",
    "torch.save(model.state_dict(), \"dha_model_final.pth\")\n",
    "print(\"Training complete. Final model saved to dha_model_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbe8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "num_joints    = 20\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [1024, 1024]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "batch_size    = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs    = 1000\n",
    "device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_tensor, y_tensor = torch.load('dataset.pt')  # X: [N,182], y: [N]\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "save_interval = 100\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# 4) 모델·옵티마이저·손실함수 초기화\n",
    "model = Skeleton2Mesh(\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs, T_mult=2, eta_min=1e-4)\n",
    "\n",
    "# alpha = 5.0\n",
    "# weights = torch.cat([\n",
    "#     torch.full((1,), 2),\n",
    "#     torch.full((3,), alpha),  # first 4 dims have weight alpha\n",
    "#     torch.ones(4)             # last 4 dims have weight 1.0\n",
    "# ], dim=0).to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5. Usage example in training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# weights_sum = weights.sum()\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "   model.train()\n",
    "   train_loss = 0.0\n",
    "   for skeletons_flat_batch, angles_batch in train_loader:\n",
    "       skeletons_flat_batch = skeletons_flat_batch.to(device)\n",
    "       angles_batch         = angles_batch.to(device)\n",
    "\n",
    "       preds = model(skeletons_flat_batch)     # [B,8]\n",
    "       loss  = criterion(preds, angles_batch)\n",
    "\n",
    "    #    loss_per_sample = (loss_matrix * weights).sum(dim=1) / weights_sum\n",
    "    #    loss = loss_per_sample.mean()\n",
    "    \n",
    "       optimizer.zero_grad()\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "\n",
    "       train_loss += loss.item() * skeletons_flat_batch.size(0)\n",
    "\n",
    "   train_loss /= train_size\n",
    "\n",
    "   # 6) 검증\n",
    "   model.eval()\n",
    "   val_loss = 0.0\n",
    "   with torch.no_grad():\n",
    "       for skeletons_flat_batch, angles_batch in val_loader:\n",
    "           skeletons_flat_batch = skeletons_flat_batch.to(device)\n",
    "           angles_batch         = angles_batch.to(device)\n",
    "\n",
    "           preds = model(skeletons_flat_batch)\n",
    "           lm = criterion(preds, angles_batch)\n",
    "        #    lps = (lm * weights).sum(dim=1) / weights_sum\n",
    "        #    loss_v = lps.mean()\n",
    "\n",
    "           val_loss += lm.item() * skeletons_flat_batch.size(0)\n",
    "   val_loss /= val_size\n",
    "\n",
    "   print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "# Example variables: epoch (int), model (nn.Module), optimizer (Optimizer), loss_value (float)\n",
    "# Adjust 'checkpoint_path' as 원하는 파일명 또는 경로로 변경하세요.\n",
    "   if epoch % save_interval == 0 or epoch == num_epochs:\n",
    "       checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': val_loss\n",
    "            }\n",
    "\n",
    "       checkpoint_path = 'checkpoint_euler_epoch{}_ver3.pth'.format(epoch)\n",
    "       torch.save(checkpoint, checkpoint_path)\n",
    "       print(f\"Checkpoint saved to {checkpoint_path} (epoch {epoch}, loss {val_loss:.6f})\")\n",
    "   scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e8e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 32 arrays to euler_epoch1000_ver3.npz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1) Load the checkpoint from .pth file\n",
    "#    If the file contains a dict with 'model_state_dict', use that;\n",
    "#    otherwise assume it _is_ the state_dict.\n",
    "checkpoint = torch.load('checkpoint_euler_epoch1000_ver3.pth', map_location='cpu')\n",
    "state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "\n",
    "# 2) Convert each tensor in the state_dict to a NumPy array\n",
    "np_params = {}\n",
    "for name, tensor in state_dict.items():\n",
    "    # Ensure the tensor is on CPU and convert to numpy\n",
    "    np_params[name] = tensor.detach().cpu().numpy()\n",
    "\n",
    "# 3) Save all arrays into a single .npz file\n",
    "#    Keys in the archive will match the original parameter names.\n",
    "np.savez('euler_epoch1000_ver3.npz', **np_params)\n",
    "\n",
    "print(f\"Saved {len(np_params)} arrays to euler_epoch1000_ver3.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa28ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (mean over all outputs): 5.143120\n",
      "Test MAE (mean over all outputs): 1.658323\n",
      "Per-output RMSE: [2.8750231 2.0619373 1.7064626]\n",
      "Per-output MAE:  [2.1378648 1.5944549 1.2426484]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Load test data\n",
    "X_test, y_test = torch.load('test.pt',weights_only=False)\n",
    "\n",
    "# 1) Device 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3) Hyperparameters / model config\n",
    "num_joints    = 20\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [1024, 1024]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "# 4) Instantiate model and load checkpoint\n",
    "model = Skeleton2Mesh(\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ").to(device)\n",
    "\n",
    "# Path to saved checkpoint\n",
    "checkpoint_path = \"checkpoint_euler_epoch1000_ver3.pth\"  # 실제 파일명으로 변경\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# If optimizer state or epoch 등 추가 정보가 필요하면\n",
    "# epoch_loaded = checkpoint.get('epoch')\n",
    "# loss_loaded = checkpoint.get('loss')\n",
    "\n",
    "# 5) Prepare test data\n",
    "#    Assume you have NumPy arrays:\n",
    "#      skeletons_test_np: shape [N_test, num_joints*3]\n",
    "#      angles_test_np:    shape [N_test, 8]\n",
    "#    These must be prepared beforehand.\n",
    "import numpy as np\n",
    "# Example placeholders; 실제 데이터를 여기에 할당하세요.\n",
    "# skeletons_test_np = np.load(\"skeletons_test.npy\")  # [N_test, 63]\n",
    "# angles_test_np    = np.load(\"angles_test.npy\")     # [N_test, 8]\n",
    "\n",
    "# Convert to torch.Tensor\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64  # 필요에 따라 변경\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 6) Define evaluation metrics\n",
    "mse_loss_fn = nn.MSELoss(reduction='mean')\n",
    "mae_loss_fn = nn.L1Loss(reduction='mean')\n",
    "\n",
    "# Optional: per-dimension metrics\n",
    "num_outputs = y_test.shape[1]  # e.g. 8\n",
    "\n",
    "# Containers for aggregated results\n",
    "total_mse = 0.0\n",
    "total_mae = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "# If you want per-output errors, accumulate sums:\n",
    "sum_sq_errors = torch.zeros(num_outputs, device=device)\n",
    "sum_abs_errors = torch.zeros(num_outputs, device=device)\n",
    "\n",
    "# 7) Evaluation loop\n",
    "with torch.no_grad():\n",
    "    for skeletons_flat_batch, angles_batch in test_loader:\n",
    "        skeletons_flat_batch = skeletons_flat_batch.to(device)  # [B, num_joints*3]\n",
    "        angles_batch         = angles_batch.to(device)         # [B, 8]\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(skeletons_flat_batch)  # [B, 8]\n",
    "\n",
    "        # Compute batch losses\n",
    "        batch_mse = mse_loss_fn(preds, angles_batch)  # scalar\n",
    "        batch_mae = mae_loss_fn(preds, angles_batch)  # scalar\n",
    "\n",
    "        # Accumulate weighted by batch size\n",
    "        B = skeletons_flat_batch.size(0)\n",
    "        total_mse += batch_mse.item() * B\n",
    "        total_mae += batch_mae.item() * B\n",
    "        num_samples += B\n",
    "\n",
    "        # Per-output accumulation\n",
    "        # Compute squared error and abs error per sample per dimension\n",
    "        diff = preds - angles_batch  # [B, 8]\n",
    "        sum_sq_errors += torch.sum(diff * diff, dim=0)    # [8]\n",
    "        sum_abs_errors += torch.sum(torch.abs(diff), dim=0)  # [8]\n",
    "\n",
    "# 8) Final metrics\n",
    "mean_mse = total_mse / num_samples\n",
    "mean_mae = total_mae / num_samples\n",
    "\n",
    "# Per-output RMSE and MAE\n",
    "rmse_per_output = torch.sqrt(sum_sq_errors / num_samples)  # [8]\n",
    "mae_per_output  = sum_abs_errors / num_samples            # [8]\n",
    "\n",
    "print(f\"Test MSE (mean over all outputs): {mean_mse:.6f}\")\n",
    "print(f\"Test MAE (mean over all outputs): {mean_mae:.6f}\")\n",
    "print(\"Per-output RMSE:\", rmse_per_output.cpu().numpy())\n",
    "print(\"Per-output MAE: \", mae_per_output.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee24649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.206814682346651\n",
      "0.7473673742849708\n",
      "0.7024254144227672\n",
      "0.6089446878829069\n",
      "0.5842644464923961\n",
      "0.5384927660721625\n",
      "0.5220780326945572\n",
      "0.5117141604423523\n",
      "0.49837305498610357\n",
      "0.4976469677222338\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "# Path to saved checkpoint\n",
    "    checkpoint_path = f\"checkpoint_euler_epoch{i*100}_ver3.pth\"  # 실제 파일명으로 변경\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    print(checkpoint['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40824381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib              # joblib is better for sklearn objects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) Load the fitted scaler\n",
    "scaler = joblib.load('y_scaler.pkl')\n",
    "\n",
    "# 2) Inverse transform normalized predictions and targets\n",
    "\n",
    "\n",
    "# 3) Compute MSE on denormalized values\n",
    "mse_per_output_denorm = mean_squared_error(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    multioutput='raw_values'\n",
    ")\n",
    "avg_mse_denorm = np.mean(mse_per_output_denorm)\n",
    "print(\"Denormalized MSE per output:\", mse_per_output_denorm)\n",
    "print(f\"Average denormalized MSE: {avg_mse_denorm:.4f}\")\n",
    "\n",
    "# 4) Build comparison DataFrame\n",
    "num_outputs = y_true.shape[1]\n",
    "columns = [f\"true_{i}\" for i in range(num_outputs)] + [f\"pred_{i}\" for i in range(num_outputs)]\n",
    "df_compare = pd.DataFrame(\n",
    "    np.hstack([y_true, y_pred]),\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# 5) Inspect a specific row by index\n",
    "index_to_inspect = 1293  # ← change this to the row you want\n",
    "if not (0 <= index_to_inspect < len(df_compare)):\n",
    "    raise IndexError(f\"Index out of range: 0 ≤ idx < {len(df_compare)}\")\n",
    "\n",
    "print(f\"\\nComparison at index {index_to_inspect}:\")\n",
    "print(df_compare.loc[[index_to_inspect]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7525e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(mse_per_output, bins=10, edgecolor='black')\n",
    "plt.title('Histogram of MSE per Output')\n",
    "plt.xlabel('MSE Value')\n",
    "plt.ylabel('Number of Outputs')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_and_save_s2m_weights(pth_path: str,\n",
    "                                 output_npz_path: str,\n",
    "                                 num_joints: int,\n",
    "                                 num_bones: int,\n",
    "                                 gsd_dim: int,\n",
    "                                 mlp_hidden: list,\n",
    "                                 pe_freqs_bone: int,\n",
    "                                 pe_freqs_order: int):\n",
    "    \"\"\"\n",
    "    Load a Skeleton2Mesh checkpoint from pth_path, extract all model weights\n",
    "    into NumPy arrays, and save into output_npz_path (.npz).\n",
    "\n",
    "    Args:\n",
    "      pth_path: path to the .pth checkpoint (must contain 'model_state_dict' key).\n",
    "      output_npz_path: path (including filename) where to save the .npz file.\n",
    "      num_joints, num_bones, gsd_dim, mlp_hidden, pe_freqs_bone, pe_freqs_order:\n",
    "        the hyperparameters used to instantiate the model exactly as in training.\n",
    "    \"\"\"\n",
    "    # 1) Instantiate the model with the same config used during training\n",
    "    model = Skeleton2Mesh(\n",
    "        num_joints=num_joints,\n",
    "        num_bones=num_bones,\n",
    "        gsd_dim=gsd_dim,\n",
    "        mlp_hidden=mlp_hidden,\n",
    "        pe_freqs_bone=pe_freqs_bone,\n",
    "        pe_freqs_order=pe_freqs_order\n",
    "    )\n",
    "    # 2) Load checkpoint (map to CPU to avoid GPU dependency here)\n",
    "    checkpoint = torch.load(pth_path, map_location='cpu')\n",
    "    # Expect checkpoint to have 'model_state_dict'; if your checkpoint saved differently,\n",
    "    # adjust the key accordingly.\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        # If you saved the entire model state_dict directly:\n",
    "        state_dict = checkpoint\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # 3) Extract weights to NumPy arrays\n",
    "    np_params = {}\n",
    "    for name, param in model.state_dict().items():\n",
    "        # detach and move to CPU, then to NumPy float32\n",
    "        np_params[name] = param.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # 4) Save into .npz\n",
    "    np.savez(output_npz_path, **np_params)\n",
    "    print(f\"Saved {len(np_params)} arrays to {output_npz_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assume you have a checkpoint at 's2m_epoch100.pth'\n",
    "# and you used these hyperparameters during training:\n",
    "num_joints    = 20    # as in your code\n",
    "num_bones     = 19\n",
    "gsd_dim       = 100\n",
    "mlp_hidden    = [256, 256]\n",
    "pe_freqs_bone = 5\n",
    "pe_freqs_order= 2\n",
    "\n",
    "checkpoint_path = 'checkpoint_ori_epoch1800.pth'   # change to your actual checkpoint filename\n",
    "output_npz_path = 'skeleton2angle_ori.npz'\n",
    "\n",
    "extract_and_save_s2m_weights(\n",
    "    pth_path=checkpoint_path,\n",
    "    output_npz_path=output_npz_path,\n",
    "    num_joints=num_joints,\n",
    "    num_bones=num_bones,\n",
    "    gsd_dim=gsd_dim,\n",
    "    mlp_hidden=mlp_hidden,\n",
    "    pe_freqs_bone=pe_freqs_bone,\n",
    "    pe_freqs_order=pe_freqs_order\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc76e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with your actual .npz path\n",
    "npz_path = 'skeleton2angle_ori.npz'\n",
    "\n",
    "try:\n",
    "    data = np.load(npz_path)\n",
    "    print(f\"Loaded .npz file: {npz_path}\")\n",
    "    print(f\"Found {len(data.files)} arrays:\\n\")\n",
    "\n",
    "    for key in data.files:\n",
    "        arr = data[key]\n",
    "        shape = arr.shape\n",
    "        ndim = arr.ndim\n",
    "\n",
    "        # Heuristic classification:\n",
    "        if ndim == 2:\n",
    "            # 2D weight: likely Linear.weight\n",
    "            # shape = (out_features, in_features)\n",
    "            print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => likely Linear.weight\")\n",
    "        elif ndim == 1:\n",
    "            # 1D: could be LayerNorm.weight or LayerNorm.bias or Linear.bias.\n",
    "            # 추가적으로 이름으로 유추:\n",
    "            if key.endswith('.weight'):\n",
    "                # 1D weight: if preceding layer is LayerNorm(prev_dim), then this is LayerNorm.weight.\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D weight: likely LayerNorm.weight\")\n",
    "            elif key.endswith('.bias'):\n",
    "                # 1D bias: could be LayerNorm.bias or Linear.bias.\n",
    "                # 이름만으로 구분이 어려우므로, 앞의 인덱스와 shape를 보고 추론 필요.\n",
    "                # 예: ffn.0.bias shape=(182,)인데, ffn.0.weight도 (182,)이므로 LayerNorm.bias.\n",
    "                #     ffn.1.bias shape=(512,)인데 weight shape (512,182)이면 Linear.bias.\n",
    "                # 간단히 두 가지 모두 가능하다고 표시:\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D bias: LayerNorm.bias or Linear.bias\")\n",
    "            else:\n",
    "                print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => 1D array: unknown role\")\n",
    "        else:\n",
    "            print(f\"  - {key}: shape={shape}, dtype={arr.dtype} => unexpected ndim={ndim}\")\n",
    "\n",
    "    # 추가로, 1D bias가 Linear.bias인지 LayerNorm.bias인지 정확히 구분하려면:\n",
    "    print(\"\\nAdditional check for 1D bias vs LayerNorm.bias:\")\n",
    "    for key in data.files:\n",
    "        if key.endswith('.bias') and data[key].ndim == 1:\n",
    "            idx = key.split('.')[1]  # 'ffn.<idx>.bias'\n",
    "            weight_key = f\"ffn.{idx}.weight\"\n",
    "            if weight_key in data.files:\n",
    "                w = data[weight_key]\n",
    "                if w.ndim == 1 and w.shape == data[key].shape:\n",
    "                    # weight도 1D, bias shape 같음 → LayerNorm.bias\n",
    "                    role = \"LayerNorm.bias (matched 1D weight)\"\n",
    "                elif w.ndim == 2 and w.shape[0] == data[key].shape[0]:\n",
    "                    # weight is 2D with out_features equal bias length → Linear.bias\n",
    "                    role = \"Linear.bias (matched 2D weight out_features)\"\n",
    "                else:\n",
    "                    role = \"Unknown bias role\"\n",
    "            else:\n",
    "                role = \"No matching weight key; unknown\"\n",
    "            print(f\"  - {key}: shape={data[key].shape} => {role}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {npz_path}. Please ensure the file exists or update the path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or processing the npz file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
